{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, sys, math, random, glob, shutil, time, functools, itertools\nfrom pathlib import Path ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers \nimport tensorflow.signal as tfs \n\nfrom scipy.io import wavfile \nfrom IPython.display import Audio, display","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Environment Constants","metadata":{}},{"cell_type":"code","source":"SEED = 1337\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\nSR = 16000\nSEGMENT_SEC = 2.0\nSEGMENT = int(SR * SEGMENT_SEC)\nN_FFT = 1024 \nHOP = 256\nWIN_LENGTH = 1024 \nN_MELS = 128\nPAD_MODE = 'REFLECT'\n\nBATCH_SIZE = 8\nEPOCHS = 15\nSTEPS_PER_EPOCH = 600\nVAL_STEPS = 80\nLEARNING_RATE = 3e-4 \nWARMUP_STEPS = 500\nEMA_DECAY = 0.999\nCHECKPOINT_DIR = '/kaggle/working/denoiser_ckpt'\nEXPORT_DIR = '/kaggle/working/denoiser_export'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(CHECKPOINT_DIR, exist_ok = True)\nos.makedirs(EXPORT_DIR, exist_ok = True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Audio Utility IO functions","metadata":{}},{"cell_type":"code","source":"def norm_audio(x):\n    x = np.asarray(x, dtype=np.float32)\n    mx = np.max(np.abs(x)) + 1e-9\n    return x / mx","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_wav_mono(path, target_sr=SR):\n    sr,y = wavfile.read(path)\n    y = y.astype(np.float32)\n    if y.ndim == 2:\n        y = y.mean(axis=1)\n    if sr!= target_sr:\n        y = tf.audio.resample(y, sr, target_sr).numpy()\n    return norm_audio(y), target_sr","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def write_wav(path, y, sr=SR):\n    y = np.asarray(y, dtype=np.float32)\n    y = (y/(np.max(np.abs(y)) + 1e-9)*0.99)\n    # scaling up from [-1, 1] to 32767\n    wavfile.write(path, sr, (y*32767.0).astype(np.int16))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Signal Transforms","metadata":{}},{"cell_type":"code","source":"# performs short time fourier transform \n# outputs 2d array of complex numbers\ndef stft(sig):\n    return tfs.stft(\n        sig, \n        frame_length=WIN_LENGTH, # how many samples to look at once\n        frame_step=HOP, # how much to hop forward, in our case 1024 - 256 samples will be overlapped\n        fft_length=N_FFT # how many frequency bins result from each analysis\n        window_fn=tf.signal.hann_window # smooths edges to avoid sharp transitions\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# converts time frequency complex representation to time domain audio signal\ndef istft(stft_c, length):\n    return tfs.inverse_stft(\n        stft_c,\n        frame_length=WIN_LENGTH,\n        frame_step=HOP,\n        window_fn=tf.signal.hann_window,\n        output_length=length\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def complex_mag(stft_c):\n    return tf.abs(stft_c)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eps():\n    return 1e-8","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# goes from linear resolution to mel_resolution\n# lower frequency bins are spaced close together (small pitch differences noticable to humans)\nMEL_FILTER = tfs.linear_to_mel_weight_matrix(\n    num_mel_bins=N_MELS,\n    num_spectogram_bins=N_FFT/2 + 1, # linear frequency bins from STFT input\n    sample_rate=SR,\n    lower_edge_hertz=0.0,\n    upper_edge_hertz=SR/2 # Nyquist frequency (half the sample rate)\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualization functions","metadata":{}},{"cell_type":"markdown","source":"## Synthetic Noise Generator (Clean and Noisy dataset)","metadata":{}},{"cell_type":"code","source":"def gen_tone(duration, sr=SR):\n    t = np.linspace(0, duration, int(sr*duration), endpoint=False)\n    # generating a time array 16k points per sec\n    f0 = np.random.uniform(100, 1000) # base frequency\n    y = np.sin(2*np.pi*f0*t) # pure sine wave at frequency f0\n    # blend pure freqency with chirp with 50% probab\n    if np.random.rand() < 0.5:\n        f1 = np.random.uniform(200, 2000)\n        # tone whose frequency changes over time, keeps changing from f0 to f1 linearly\n        chirp = np.sin(2*np.pi*(f0 + (f1-f0)*t/duration)*t)\n        y = 0.6*y + 0.4*chirp\n    env = 0.5*(1-np.cos(2*np.pi*np.minimum(1.0, t/duration)))\n    # smooth cosine curve controlling volume over time, prevents sudden starts or stops\n    return norm_audio(y * env)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def gen_noise(duration, sr=SR):\n    n = int(sr*duration)\n    # white noise: energy concentration equal\n    white = np.random.randn(n).astype(np.float32)\n    freqs = np.fft.rfftfreq(n, 1/sr) # 1d array\n    # pink noise: energy concentrate more at lower frequency\n    pink_spec = (np.random.randn(len(freqs))+1j*np.random.randn(len(freqs)))/np.maximum(freqs, 1.0)\n    # random complex numbers to generate noise, frequency below zero stays same\n    pink = np.fft.irfft(pink_spec, n=n).astype(np.float32)\n    # convert back to time domain\n    babble = np.zeros(n, dtype=np.float32)\n    # summing up several tones (3 to 6) to simulate overlapping sounds\n    for _ in range(np.random.randint(3, 7)):\n        babble += gen_tone(duration, sr)\n    babble = babble / (np.max(np.abs(babble)) + 1e-9)\n    mix = 0.5*white/np.max(np.abs(white)+1e-9) + 0.3*pink/np.max(np.abs(pink)+1e-9) + 0.2*babble\n    return norm_audio(mix)\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def random_segment(y, length):\n    if len(y) < length:\n        pad = length - len(y)\n        y = np.pad(y, (0, pad), mode='reflect')\n        return y\n    start = np.random.randint(0, len(y)-length)\n    return y[start:start+length]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mix_clean_noise(clean, noise, snr_db=None):\n    if snr_db is None:\n        snr_db = np.random.uniform(-5, 15)\n    # normalizing both\n    c = clean / (np.std(clean)+1e-9)\n    n = noise / (np.std(noise)+1e-9)\n    # getting rms of both signals\n    rms_c = np.sqrt(np.mean(c**2)+1e-9)\n    rms_n = np.sqrt(np.mean(n**2)+1e-9)\n    target_rms_n = rms_c / (10**(snr_db/20.0))\n    # scaling the noise to get the desired ratio\n    n = n * (target_rms_n / (rms_n + 1e-9))\n    noisy = c + n\n    return norm_audio(noisy), norm_audio(c), norn_audio(n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pipeline","metadata":{}},{"cell_type":"code","source":"def wav_loader_factory(clean_paths, noise_paths):\n    # loader function yields one noisy, clean pair (is iterable)\n    def load_and_mix(_):\n        if clean_paths:\n            cp = random.choice(clean_paths)\n            c, _sr = read_wav_mono(cp, SR)\n        else:\n            c = gen_tone(SEGMENT_SEC)\n        if noise_paths and np.random.rand() < 0.9:\n            npth = random.choice(noise_paths)\n            n, _sr = read_wav_mono(npth, SR)\n        else:\n            n = gen_noise(SEGMENT_SEC + 1.0)\n        c_seg = random_segment(c, SEGMENT)\n        n_seg = random_segment(n, SEGMENT)\n        # noisy will be the model input and clean will be the target\n        noisy, clean, noise = mix_clean_noise(c_seg, n_seg)\n        return noisy.astype(np.float32), clean.astype(float32)\n    return load_and_mix\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example workflow:\n# For an example step size of 600\n# Each call to loader function returns a (noisy, clean) pair, ((32000,), (32000,))\n# Gen functions inside tf_dataset calls the loader function 600 * 8 * 2 = 9600 times\n# For each epoch a fresh pool is generate 9600 new samples\n# The samples are shuffled\n# From this pool, batches of 8 are created, so in total 600 batches of 8 samples are created\n# Train_ds is an iterable object\n# Calling next() on it yields one batch -> ((8, 32000), (8, 32000))\n# You can call the next function 600 times\n\ndef tf_dataset(clean_paths, noise_paths, batch_size, steps):\n    # generator function to call the loader function 2 * required amount times (helps in shuffling)\n    def gen(): # stream\n        loader = wav_loader_factory(clean_paths, noise_paths)\n        for _ in range(steps * batch_size * 2):\n            yield loader(None)\n    # output dimensions\n    output_sig = (tf.TensorSpec(shape=(SEGMENT,), dtype=tf.float32),\n                  tf.TensorSpec(shape=(SEGMENT,), dtype=tf.float32))\n    # reiterable (generates fresh pool for every epoch)\n    ds = tf.data.Dataset.from_generator(gen, output_signature=output_sig)\n    ds = ds.shuffle(8192, reshuffle_each_iteration=True)\n    ds = ds.batch(batch_size, drop_remainder=True)\n    # asynchronously preparing the next batch while the current one is being processed\n    ds = ds.prefetch(tf.data.AUTOTUNE)\n    return ds\n\ntrain_ds = tf_dataset(CLEAN_WAVS, NOISE_WAVS, BATCH_SIZE, STEPS_PER_EPOCH)\nval_ds = tf_dataset(CLEAN_WAVS, NOISE_WAVS, BATCH_SIZE, VAL_STEPS)\n\nnoisy_b, clean_b = next(iter(train_ds))\nprint(\"Batch shapes:\", noisy_b.shape, clean_b.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"# layer friendly stft functions \n# input: (Batch, Datapoints): eg (8, 32000) for 2 sec sample\ndef stft_layer(x):\n    X = tf.numpy_function(lambda a: tfs.stft(a, WIN_LENGTH, HOP, N_FFT, window_fn=tf.signal.hann_window).numpy(),\n                         [x], Tout=tf.complex64)\n    X.set_shape([None, None, N_FFT//2 + 1])\n    return X","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class STFTMagLayer(layers.Layer):\n    def call(self, x):\n        # input : (8, 32000)\n        # output: (8, 122, 513)\n        X = tfs.stft(x, frame_length=WIN_LENGTH, frame_step=HOP, fft_length=N_FFT,\n                    window_fn=tf.signal.hann_window) # outputs array of complex numbers\n        mag = tf.abs(X) # magnitude\n        phase = tf.math.angle(X) # phase \n        # helpful for reconstructing audio in inverse stft\n        return tf.transpose(mag, [0, 1, 2]), tf.transpose(phase, [0, 1, 2]), X","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def db_log(x):\n    return tf.math.log(x+ 1e-6)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inv_db_log(x):\n    return tf.math.expm1(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unet_block(x, filters, name, down=True):\n    if down:\n        x = layers.Conv2D(filters, 3, strides=2, padding='same', name=name+'_conv')(x)\n        x = layers.BatchNormalization(name=name+'_bn')(x)\n        x = layers.Activation('relu', name=name+'_relu')(x)\n        return x\n    else:\n        x = layer.Conv2DTranspose(filters, 3, strides=2, padding='same', name=name+'_deconv')(x)\n        x = layers.BatchNormalization(name=name+'_bn')(x)\n        x = layers.Activation('relu', name=name+'_relu')(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}